---
title: "Persuasion Susceptibility in r/ChangeMyView | An Exploration of Self-Affirmation, Reciprocation, and other Historical Information"
author: "Julian McClellan"
date: "April 1, 2018"
output: 
  pdf_document:
    toc: true
    latex_engine: xelatex
    includes:
      in_header:
        header.tex
bibliography: citations.bib
---

# Abstract

Using information from the good faith debate subreddit r/ChangeMyView, this paper
utilizes historical information on users who submit their opinion in this debate
space, in order to see whether this information can be used to predict whether
said users will end up changing their opinion in the face of persuasion. Some
user history is evaluated under the psychological theory of self-affirmation, in
an attempt to test the  theory's viability in an online context. Another concept
tested is the idea of "community reciprocity", where users' susceptibility to
persuasion is correlated with their previous attempts to change other user
opinions. Additional user information, not directly applicable to reciprocity or
self-affirmation,  is utilized as a means of classing similar users.


# Introduction

# Data

## Overview of Data Source: r/ChangeMyView

The popular social media site, Reddit, is composed of a variety of subcommunities, or "subreddits". One such subreddit, r/ChangeMyView (CMV):

> . . . is a subreddit dedicated to the civil discourse of opinions, and is built around
the idea that in order to resolve our differences, we must first understand them.
We believe that productive conversation requires respect and openness, and that
certitude is the enemy of understanding.
 
Redditors can participate in CMV in one of two main ways. They can post their *opinions*,
along with supporting reasoning, as *submissions*, or they can *comment* directly on  a submission in an
*attempt to change the opinion*. If a user posts a view, the subreddit's rules
require them to respond to any comments, attempts to change the view, within
three hours otherwise the post is removed. The rules of CMV also 
forbid low effort comments, and an active team of moderators stringently enforce all of CMV’s
rules. If a respondent mangages to change the original poster’s (OP) opinion, then the OP can
award the comment that changed his or her mind a “delta”, by replying directly to the worthy 
comment with a signal that a delta has been awarded (typically "!delta"), along with a brief explanation
of why the comment changed their view. While uncommon, it is also possible for
another user that is not the OP, who one might presume holds a similar view, to award deltas as well.

![Example of an Opinion](figs/cmv_opinion.png)
![OP interacts with respondent and awards a "Delta". "DeltaBot"" confirms the delta, adding to the display of awarded deltas for the user "velvykat5731" ](figs/cmv_response.png) 

Before the delta is officially awarded to a respondent, a bot (*DeltaBot*) must confirm it.
Assuming the OP's explanation is long enough (a sentence or two), DeltaBot responds to the 
OP's delta signalling comment to confirm the award. After this confirmation, any
comment that the user who received the delta makes, will have an updated total
of deltas awarded to the right of their name. This confirmation also contributes
to a record of deltas on a separate subreddit, r/DeltaLog, a browseable archive
of comments that received deltas in r/ChangeMyView. Additionally, the wiki of r/ChangeMyView 
also features a Deltaboards section which tracks the users with the most deltas
awarded daily, weekly, and monthly.

![The Front Page of r/DeltaLog. Delta winning comments are sorted by submission.](figs/delta_log.png)

![Weekly and Monthly Sections of the Deltaboards](figs/delta_boards.png)

Thus, the CMV subreddit allows for access to the reasoning behind a person’s
views, the debate that takes place for each view, and an easily extractable
outcome of the debate: either the opinion is stable and no delta is awarded, or
the opinion changes, and at least one delta from the OP is awarded. CMV is an ideal setting
for the study of persuasion (@tan2016winning). There are many questions to be
explored in CMV, but one that leverages the open nature of Reddit user histories is:

> "Using what we know about a user who submits a view to CMV, can we predict if they will
change their opinion?"

## Exploring the Data Used

```{r, echo=FALSE, message=FALSE, results='hide'}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
source("explore_data.R")

expl <- explore_data()

pretty_percent <- function(float){
  require(glue)
  float <- signif(float, digits = 3)
  (as.character(glue("{float}%")))
}
```

Firstly, in order to answer this question, opinions must be gathered. Because
Reddit submissions are "archived", i.e. made immutable, once they are 6 months old
I look at the opinion submissions posted to CMV in 2016, and the authors of
these submissions. While there is no doubt that 2016 opinion submissions fit
into and contain distinct time series patterns for many of the covariates I
analyze, I make a tradeoff between "all" archived CMV submisions (2013 to today - 6 months) and too few. In
choosing a year's worth of *relatively* recent data, I aim to average over fewer
distinct times trends, maintain statistical power, and to counteract the
remaining possibility, for older archived submissions, that a Reddit users
deletes or edits their submissions. Because this study aims to gather
information on Reddit user's partially through their submission history,
deletions and edits create introduce anomalies in the data that are difficult to
counteract. Deletions are a missing data problem with no practical imputation solutions,
and while one can tell whether a submission is edited, there is no way to reliably
count the number of edits or discern the changes made. Additionally, a number of
older significant CMV submissions are authored by "[deleted]", i.e. an unknown
author. A Reddit user can delete there account, and henceforth all of their submissions
will appear to be authored by "[deleted]".

Due to the risk of account deletion teogether with submission alteration and/or deletion,
the time at which data is important to note, as later versions of the same Reddit content
may very well be different from their earlier versions. Starting February 19th, 2018, I 
utilized PRAW, The Python Reddit API Wrapper, with a MySQL database to begin
scraping data from CMV opinion submissions from 2016. All the content of these
opinion submissions were gathered. In the vast majority of cases in which an opinion
submission author could be identified, of the submissions the author made before
the time of the scraping were also gathered. On February 28th the data was backed
up and ready to process. To reiterate generally, 2 major sources of data were gathered:

  * All CMV opinion submissions and their content
  * All available CMV authors' submission histories
    + Comments to these submissions were not tracked.

In 2016, `r nrow(expl$cmv_subs)` opinion submissions were recorded in CMV. Of
these, `r pretty_percent(sum(expl$cmv_subs$gave_delta) / nrow(expl$cmv_subs))`
of these opinions are recorded as having changed by their OP. Below are figures
detailing day-by-day and hour-to-hour opinion submission activity by their resulting change in opinion,
or lack thereof.

```{r}
require(lubridate)
(
  expl$plots$all_activity + 
   labs(title = "2016 CMV Submission Activity",
        subtitle = "by opinion change status",
     fill = "Opinion Change?") + 
    geom_vline(aes(xintercept = as.numeric(ymd("20161108"))),
               linetype = 1, color = "gray") + 
  geom_text(mapping=aes(x=ymd("20161108"), y=0, label="2016 Election"), size=4, angle=90, vjust=-0.4, hjust=-2.2)
 )

(
  expl$plots$day_activity +
    labs(title = "2016 CMV Submission Activity by Hour",
         subtitle = "24 Hours | UTC",
         x = "Hour of the Day",
         fill = "Opinion Change?"
         )
)
```

`r sum(expl$cmv_subs$auth_first)` 2016 opinion submission were made by first
time authors. Indeed, first time authors with submission history are the subjects of interest in
this study (hereafter: subject authors). After all, without some sort of prior
Reddit participation, there is very little information to discern from subject
authors. There are many that have at least 1 prior submission in a subreddit
other than r/ChangeMyView, and some even have hundreds of prior submissions. Of
course, some submissions are older, relative to that author's first CMV opinion,
than others. Should a submission from 2013 be taken into account for it's potential
effect on a CMV opinion given in 2016? Deciding on a cutoff, if to have one at all introduces another
tradeoff, one the one hand, a shorter cutoff, say only including the last 30 days 
worth of submissions before a subject author's first CMV opinion allows only the recent, and 
perhaps most relevant information of that author to be taken into account. However,
a short cutoff also precludes more subject authors from study, given the higher bar
on activity demanded from the cutoff. A longer cutoff, or not having a cutoff at all
includes more subject authors in the study, with all possible information, but
information gleaned from older submissions might be "noise" to our model that
attempts to predict whether the further off opinion changes or not.

In light of these tradeoffs (which are heuristics at best), I begin by including
only submission histories that are no more than 1 year older than a CMV author's
first CMV opinion. If an author does not have submission history within one year
of their first CMV opinion, they are not counted as subject authors. Given this criteria,
`r nrow(expl$model_dat)` (`r pretty_percent(nrow(expl$model_dat) / sum(expl$cmv_subs$auth_first))`),
viable subject authors are available for study. A density figure of the number of submission prior to a subject
author's first CMV submission is given below.

```{r}
median_prev_sub <- median(expl$model_dat$`(AH) # Submissions within 1 years before 1st CMV Post`)

(
 expl$plots$prev_subs_density + 
   labs(title = "Subject Author Submissions Prior to First CMV Opinion",
        subtitle = glue("Within 1 year of 1st Opinion | Median ({median_prev_sub}) Marked"),
        x = "Previous Submissions") +
    geom_vline(aes(xintercept = median_prev_sub), linetype = 3)
)
```

Accordingly then, from my two major sources of data, 2016 CMV opinions, and the
submission histories of their author's I have narrowed down my scope of inquiry
to the opinions and submission histories of the subject authors. These subject authors
are those Reddit users who have:
  
  1. Submitted their first opinion to CMV in 2016
  2. Have at least 1 Submission within a year before their first CMV opinion.
  
With the specific population of interest specified, features can be constructed and
categorized to provide the best attempt at predicting whether subject authors' opinions
changed.

# Methodology

## Features

I construct three distinct groups of features to utilize in my model. . .
  * Author History (AH)
  * Pre Debate
  * Post Debate
  
### Author History

As the title suggests, this group of features focuses on the subject author's submission
history.

#### Submissions within 1 year before 1st CMV Post

As alluded to above, this feature is a simple count of the subject author's submissions
within a year before his or her first CMV Post. Since all the submissions included
in this feature are subreddits that are *not* CMV, it fits nicely within self-affirmation's conception
of success in an unrelated field, especially when paired with other author history
features like "Mean Submission Score".

#### Unique Subreddits Posted In

For the subject author's submission history, this counts how many distinct subreddits
the author participated in before posting to CMV.

#### Average Previous Submission Date

This feature seeks to establish the chronological "center" of the subject
author's submission history.

#### Edits Per Previous Submission

If a subject author edits one of their previous post, any number of times, this
can be tracked with the Reddit API. Edits occur for a variety of reasons, and may
help indicate a user's responsiveness to comments on their submissions. For CMV
submission this is usually the case, so I track previous, potentially similarly
motivated behavior with this feature.

#### Fraction Plural First Person Pronouns
#### Fraction Singular First Person Pronouns
#### Mean Plural First Person Pronouns
#### Mean Singular First Person Pronouns

@tan2016winning found:

> First person pronouns are strong indicators of malleability, but first person
plural pronouns correlate with resistance. . . individualizing
one’s relationship with a belief using first person pronouns
affirms the self, while first person plurals can indicate a diluted
sense of group responsibility for the view

In light of this, I have included a number of features concerning plural and
singular first person pronouns, with the mean based ones being more sensitive to
submission length (and thus, in many cases, quality), and the fraction based features
being agnostic to the number of submissions and their length.

#### Mean # of Words

This feature serves as a proxy for mean prior submission quality, and is also
included to calculate first person pronoun fractions.

#### Mean Previous Submission Sentiment

Utilizing the R package "sentimentr" I calculate a negative-positive (-1 to 1)
sentiment score and take the average across the subject author's previous
submissions.

#### Mean Submission Score

This is simply the average of all the subject author's previous submissions. While
Reddit upvote/score manipulation is impossible to rule out, this helps to delineate
the "success" of self-affirmation provided by the submissions.

#### Removed CMV Subs 1 Year before 1st CMV Post

This feature counts the subject author's previous "unsuccessful" earlier attempts
at posting to r/ChangeMyView. CMV posts counted in this feature are those that
are removed for some violation of the rules of the subreddit. Given the self-selective
nature of CMV participants, unsucessful earlier integration into the community
as measured through removed CMV posts could be an important feature to keep track
of.

#### Submissions with Content 1 Year before 1st CMV Post

Not all submissions are created equal, at least compared to the higher quality
discussion and opinion explanations found on CMV. This feature counts the number
of subject author submissions that actually have textual content beyond, say, a
hyperlink.

#### Subreddit Gini Index

This feature is a measure of subreddit submission inequality. This feature helps
to differentiate between subject author's who focused a lot of their submissions
in a few subreddits versus those who diversified the subreddits they posted
submissions in.

### Pre Debate

This features are based on the subject author's first opinion submitted to CMV,
but utilizing information that could only be gleaned at the time of the submission,
before any debate initiated by other user's could take place. Together with the
Author History features, these groups comprise the main thrust of the study, to
test the predictive capability of subject author information from their history 
and from their opinion on opinion malleability.

#### # Words

Counts the number of words contained within the CMV Submission.

#### CMV Submission Date

Tracks the date the subject author submitted their first opinion to CMV. (UTC Epoch)

#### CMV Submission Hour

Tracks the hour of the day the opinion was posted. (UTC 24 hours)

#### Fraction Plural First Person Pronouns
#### Fraction Singular First Person Pronouns
#### Total Plural First Person Pronouns
#### Total Singular First Person Pronouns

  

### Final Processing




Using submissions and author histroy scraped from CMV activity in 2016, I construct several
relevant features to help predict an opinion change/delta awarding. Like Tan et al. I utilize
the wording of the opinion itself, but I also go beyond and construct features from the OP’s
prior submission history. Like Tan et al. I create some features linked to self-affirmation
theory in psychology, but also utilizes features specific to the place of submissions in Reddit
overall.

I utilize weighted logistic regression models and outperform earlier attempts to predict the
opinion change on CMV. Whereas previous psychological studies have found the effects of
self-affirmation in the immediate past to be statistically significant in predicting opinion
malleability (Cohen, Aronson, and Steele 2000), the models here find that self-affirmation
features utilizing the entirety of an OP’s submission history, dating back months and sometimes
years, also have signifiant effects in the same domain. Thus, this paper provides the first
evidence to suggest that self-affirmation has such far-reaching effects.

Persuasion is a topic of a large research effort in a number of fields. There's psychology and a number of its subfields, 
of course, but also fields like international relations, linguistics, and
human-computer interaction are concerned with how persuasion is manifested in a
variety of contexts [@nye2004soft, @martin1995lingpers, @kaptein2009can]. 

```{r get_raw_dat, include=F, echo = F}
DL_DATA <- FALSE # Load data from MySQL or from disk?

library(tidyverse)
library(magrittr)
knitr::opts_chunk$set(echo = F, message = F)

dbcon <- src_mysql("jmcclellanDB", 
                   host="mpcs53001.cs.uchicago.edu",
                   username="jmcclellan",
                   password="udaeTh5b"
                  )
if (DL_DATA){
  cmv_coms <- dbcon %>%
    tbl("CMV_Comment") %>%
    collect() %>%
    filter(content != "[removed]",
           content != "[deleted]") %T>%
    write_rds("pre_model_data/cmv_coms.rds")
  
  cmv_subs <- dbcon %>%
    tbl("CMV_Submission") %>%
    collect() %>%
    mutate(gave_delta = ifelse(deltas_from_author > 0, 1, 0)) %>%
    filter(content != "[removed]") %>%
    mutate(cmv_sub_ind = 1) %T>%
    write_rds("pre_model_data/cmv_subs.rds")
  
  std_subs <- dbcon %>%
    tbl("Submission") %>%
    collect() %>%
    filter(content != "[removed]",
           content != "[deleted]") %T>%
    write_rds("pre_model_data/std_subs.rds")
  
  cmv_auths <- dbcon %>%
    tbl("CMV_Sub_Author") %>%
    collect() %T>%
    write_rds("pre_model_data/cmv_auths.rds")
    
} else {
  cmv_coms <- read_rds("cmv_coms.rds")
  cmv_subs <- read_rds("cmv_subs.rds")
  std_subs <- read_rds("std_subs.rds")
  cmv_auths <- read_rds("cmv_auths.rds")
}

```

```{r topic_creation, eval=F, echo=F}
CREATE_LDA <- FALSE # Create LDA again or load from disk?

# Followed from:
# https://cran.r-project.org/web/packages/tidytext/vignettes/topic_modeling.html
library(tidytext)
library(stringr)
library(tidyr)
library(topicmodels)
if (CREATE_LDA){
  cmv_subs_col <- cmv_subs %>% collect()
  
  by_cmv_sub_word <- cmv_subs_col %>%
    select(reddit_id, content) %>%
    unnest_tokens(word, content)
  
  word_counts <- by_cmv_sub_word %>%
    anti_join(stop_words) %>%
    count(reddit_id, word, sort = TRUE) %>%
    ungroup()
  
  cmv_dtm <- word_counts %>%
    cast_dtm(reddit_id, word, n)
  
  cmv_lda <- LDA(cmv_dtm, k = 7, control = list(seed = 1234))
  write_rds(cmv_lda, "topic_model.RData")
} else {
  cmv_lda <- read_rds("topic_model.RData")
}

# For the k topics, we create a table with reddit_id of the CMV post as the primary key
# And the "gamma" score given by the model giving the "probability" that
# document belongs to a certain topic
library(glue)
cmv_lda_doc_top <- tidy(cmv_lda, matrix = "gamma") %>%
  mutate(topic = paste("topic_", topic, sep = "")) %>%
  spread(topic, gamma) %>%
  rename(reddit_id = document)

# Join with cmv submissions
cmv_subs <- inner_join(cmv_subs, cmv_lda_doc_top)
```

```{r transform_data}
library(text2vec)
prep_fun = function(x) {
  x %>% 
    # make text lower case
    str_to_lower %>% 
    # remove non-alphanumeric symbols
    str_replace_all("[^[:alnum:]]", " ") %>% 
    # collapse multiple spaces
    str_replace_all("\\s+", " ")
}
  browser()
# subject_authors <- read_rds("subject_authors.RDS")

START_2016 <- 1451606400 # Really should have a better date system in place here. . . 
END_2016 <- 1483228800
nth_date <- function(x, order, decrease){
  u <- unique(x)
  sort(u, decreasing = decrease)[order]
}

# CMV Sub authors, their earliest CMV Submission, and the number of CMV Subs
sub_auths_min_date <- cmv_subs %>%
  group_by(author) %>%
  summarise(last_cmv_date = nth_date(date_utc, 1, T),
            first_cmv_date = nth_date(date_utc, 1, F),
            tot_cmv_subs = n())

first_cmv_subs <- inner_join(sub_auths_min_date, cmv_subs) %>%
  filter(date_utc == first_cmv_date)

# Use the min date to do grouping and filtering
                            # Add a variable to show proportion of past submissions in CMV
std_subs_info <- inner_join(std_subs %>% mutate(is_cmv_sub = ifelse(subreddit == "r/changemyview", 1, 0)), 
                            sub_auths_min_date) %>%
  filter(date_utc < first_cmv_date) %>%
  inner_join(by = "author", first_cmv_subs %>% select(author, content)) %>%
  filter(author != "[deleted]") %>%
  group_by(author) %>%
  summarise(
            # Stats from non-CMV submission before first CMV Submission  
            prev_subs = n(),
            cmv_sub_prop = sum(is_cmv_sub) / prev_subs, 
            prev_unique_subs = length(unique(subreddit)),
            prev_avg_score = mean(score),
            prev_avg_edits = mean(edited),
            prev_avg_dcoms = mean(direct_comments),
            prev_avg_tcoms = mean(total_comments),
            prev_avg_acoms = mean(author_comments),
            prev_avg_unique_parts = mean(unique_commentors),
            prev_avg_score = mean(score),
            all_text = prep_fun(paste(content.x, content.y, collapse=" ")),
            sub_text = prep_fun(paste(content.x, collapse=" ")),
            first_cmv_text = prep_fun(paste(content.y, collapse = " "))
  ) %>%
  filter(!(sub_text %in% c("", " ", "  ")))
```

```{r sim_scores}
# tfidf = TfIdf$new()
tfidf = LSA$new(n_topics = 100)

# http://text2vec.org/similarity.html
vectorizer <- prep_fun(std_subs_info$all_text) %>%
  itoken(progressbar=F) %>%
  create_vocabulary() %>%
  prune_vocabulary(doc_proportion_max = 0.1, term_count_min = 5) %>%
  vocab_vectorizer()

library(purrr)
sub_dtm <- std_subs_info$sub_text %>% itoken(., progressbar=F) %>%
  create_dtm(vectorizer) %>%
  fit_transform(tfidf)

first_cmv_dtm <- std_subs_info$first_cmv_text %>% itoken(., progressbar=F) %>%
  create_dtm(vectorizer) %>%
  fit_transform(tfidf)

par_scores <- psim2(sub_dtm, first_cmv_dtm, method = "cosine", norm = "l2")
std_subs_info <- std_subs_info %>%
  mutate(sim_scores = par_scores)

std_subs_info %>% 
  ggplot(aes(x = sim_scores)) + 
  geom_histogram(bins = 50)
```

```{r eval=F}
cmv_coms_info <- inner_join(cmv_coms, sub_auths_min_date) %>%
  # Don't count CMV comments posted on their own posts (Impossible to get a delta from yourself!)
  inner_join(cmv_subs %>% select(author, reddit_id, date_utc, direct_comments, content)
             %>% rename(sub_auth = author, sub_id = reddit_id, sub_date = date_utc), 
             by=c("parent_submission_id" = "sub_id")) %>%
  filter(sub_auth != author) %>%
  filter(date_utc < first_cmv_date) %>%
  # filter(!((author %in% subject_authors) & (sub_auth %in% subject_authors))) %>%
  mutate(cmv_com_ind = 1,
         direct_reply_ind = ifelse(is.na(parent_comment_id), 1, 0),
         
         # Create variable showing the lag time in minutes (originally ms) between
         # the CMV comment and the original post
         lag_time = abs((date_utc - sub_date) / (1000 * 60))
         ) %>% 
  group_by(author) %>%
  summarise(
            prev_cmv_coms = sum(cmv_com_ind),
            prev_cmv_direct_coms = sum(direct_reply_ind),
            prev_cmv_avg_OP_deltas = mean(deltas_from_OP),
            prev_cmv_avg_other_deltas = mean(deltas_from_other),
            prev_cmv_sub_avg_direct_coms = mean(direct_comments),
            prev_cmv_com_avg_lag = mean(lag_time),
            
  ) %>%
  mutate(delta_treatment = ifelse(prev_cmv_avg_OP_deltas > 0, 1, 0)) %>% # Only count deltas received from an OP
  mutate(delta_treatment = factor(delta_treatment, levels=c(0, 1), labels=c("No Delta", "Delta")))

cmv_sub_info <- inner_join(cmv_subs, sub_auths_min_date) %>%
  filter(date_utc <= last_cmv_date) %>%
  group_by(author) %>%
  summarise(
            prev_cmv_subs = n(),
            outcome_deltas_given = sum(gave_delta),
            outcome_delta_rate = outcome_deltas_given / prev_cmv_subs,
            deltas_from_other = sum(deltas_from_other),
  )

reg_form <- inner_join(std_subs_info, cmv_coms_info) %>%
  inner_join(cmv_auths %>% select(user_name, cmv_submissions), by=c("author" = "user_name")) %>%
  inner_join(cmv_sub_info) %>%
  filter(author != "[deleted]")

subject_authors <- unique(reg_form$author)
write_rds(subject_authors, "subject_authors.RDS")
```
# Literature Review

## Persuasion and Malleability 

Before the advent of social media websites like Facebook or Reddit, research efforts into
persuasion (and by extension, malleability) were mostly confined to laboratory settings,
but thanks to the increasing number of social interactions online, interpersonal persuasion
has become observable on a massive scale [@fogg2008mass]. Tan et al. explored persuasion in
r/ChangeMyView, [-@tan2016winning]. CMV is particularly conducive to the study of mass interpersonal
persuasion, as posters must state the reasoning behind their views, and successful arguments
must be awarded with explicit confirmation. Thus, the outcome of the persuasion efforts,
reasoning behind people’s views, and the full interactions are accessible.
With access to this information, Tan et al. focused primarily on how interaction dynamics and
choice of language within arguments were associated with a successful change in someone’s
3
opinion. A third focus of the study was an attempt to determine the malleability of an
opinion, i.e. the likelihood that the holder of that opinion would award successful arguments
to change it. Assuming that at least 10 unique challengers to the opinion were present, and
that the holder of the opinion responded at least once, Tan et al. analyzed the way in which
the opinion was presented and attempted to predict whether or not it could be changed.
This last task, attempting to determine the malleability of an opinion without respect to any
of the arguments attempting to change it, was difficult indeed, and Tan et al. only achieved
an out of sample ROC of .54 with their best model. Still, using weighted logistic regression,
they found some significant features consistent with self-affirmation theory (Cohen, Aronson,
and Steele 2000; Correll, Spencer, and Zanna 2004).

# Data

## Subjects
The subjects of interest, specifically, are Reddit users who have participated
on CMV by posting submissions (their views), but have also participated in CMV
via comments (attempting to change a view) before their first CMV submission. Of
these, there are `r nrow(reg_form)` "subject" authors meeting this criteria of
`r nrow(cmv_auths)` authors in total who posted CMV submissions in 2016. 

## Important variables.
Our treatment variable, `delta_treatment` is a binary variable indicating
whether or not the given subject author received a delta in any of their
previous CMV comments from the original poster of that comment. Also, while this
is hard to demonstrate in practice, this treatment assignment would seem to be independent 
of the potential outcomes of `outcome_deltas_given`. After all, if a subject author
is deciding whether or not responses from the CMV community change his mind,
they don't explicitly take into account whether or not they themselves had
received a delta before.

There are a number of factors that can contribute to the `delta_treatment` assignment.
Perhaps most obviously is the number of attempts (CMV comments) the subject author has made to
change the opinions of Reddit users. These are represented in the variables `prev_cmv_coms` and
`prev_cmv_direct_coms`. It is important to determine the subject author's direct
comments as well as all of their comments. A direct CMV comment replies directly
to the opinion at hand, while there are those that are more "nested" in the
discussion such as replies of replies of direct replies. While the OP of a CMV
submission is free to award nested comments with a delta, they are far more
likely to award direct comments a delta.

Some topics are more contentious than others, and given the diverse subject
matter on CMV. The subject authors might be attempting to change the opinion
concerning a humorous topic, nascent social issues, or something inspired from
the news-cycle at the time. To account for this, I create a Latent Dirichlet
Allocation (LDA) topic model that assumes 7 different topics are present in *all* 
the CMV submissions gathered in the data. Each CMV submission is then given a
score  for each of the 7 topics ($0 \leq \gamma_k \leq 1 | k={1...7} | \sum \gamma_k = 1$).
For each subject author, the average of the 7 topic scores for all the
submissions they commented on is recorded (`prev_topic_{k}_score`).

The quality and timing of the dicussion can also impact `delta_treatment`. In this study,
discussion quality is flattened into `prev_cmv_sub_avg_direct_coms`. It is important
to have a measure of discussion quality as one can imagine that the lack (or excess) of
direct comments for a given opinion might raise or lower the subject author's
chances of having their own comment awarded a delta. As for timing, previous research
has shown that comments made earlier in the life of a submission are more likely to receive a delta @tan2016winning. Thus, the average lag time between the CMV submissions and the CMV comments is present as `prev_cmv_com_avg_lag` (minutes).

# Propensity Score Stratification

## Preliminary View

Because I am interested in the effect of `delta_treatment` on
`outcome_delta_rate`, but since `delta_treatment` assignment can be affected by
some variables (as discussed above), I utilize propensity score stratification
to try and discern the average treatment effect (ATE).

Below is a basic table showing the difference in the `outcome_delta_rate`
between the two `delta_treatment` groups: "Delta" and "No Delta". There is also
a basic t-test between these two groups, showing a statistically significant
difference between the means of `outcome_delta_rate` between the two groups.

```{r prop_score_strat}
# Based off of
# https://sejdemyr.github.io/r-tutorials/statistics/tutorial8.html
library(MatchIt)
theme_set(theme_minimal())

reg_form %>%
  group_by(delta_treatment) %>%
  summarise(n_redditors = n(),
            mean_delta_rate = mean(outcome_delta_rate),
            std_error = sd(outcome_delta_rate) / sqrt(n_redditors))

with(reg_form, t.test(outcome_deltas_given ~ delta_treatment))
```

## Investigate Covariates  

In the data section, I discussed the potential of 11 covariates having affects
on `delta_treatment`. Even with a visual inspection, the variables `prev_cmv_coms`, `prev_cmv_direct_coms`, `prev_cmv_sub_avg_direct_coms`, `prev_cmv_com_avg_lag` seem to have different means across the two treatment groups.

```{r pcovs}
reg_form_cov <- c("prev_cmv_coms", "prev_cmv_direct_coms", "prev_cmv_sub_avg_direct_coms", "prev_cmv_com_avg_lag",
                  "prev_topic_1_score", "prev_topic_2_score", "prev_topic_3_score",
                  "prev_topic_4_score", "prev_topic_5_score", "prev_topic_6_score") # Full
# reg_form_cov <- c("prev_cmv_sub_avg_direct_coms", "prev_cmv_com_avg_lag", "prev_topic_3_score") # Filtered (sensitvity)
reg_form %>%
  group_by(delta_treatment) %>%
  select(one_of(reg_form_cov)) %>%
  summarise_all(funs(mean(., na.rm = T)))
```

Utilizing t-tests for each variable between the two groups we see that a number
of covariates whose means have (95%) statistically significant differences between
the values of `delta_treatment`. 

```{r pcov_t, warning=FALSE}
library(purrr)
library(knitr)
kable(
  with(reg_form, 
    map_dfr(reg_form_cov, function(v) {
      require(glue)
      test_results <- t.test(unlist(reg_form[, v]) ~ delta_treatment)
      pval <- test_results$p.value
      if (pval > .05){
        sig <- "Not Significant (95%)"
      } else {
        sig <- "Significant (95%)"
      }
        as.data.frame(list(covar = v, p_value = pval, significant = sig))
    })
  )
)
```

## Estimate Propensity Score

The propensity score will be estimated using a logit model of `delta_treatment`
on the aforementioned important covariates.

```{r est_prop_score, warning=FALSE}
form <- as.formula(paste("delta_treatment ~ ", paste0(reg_form_cov, collapse = " + ")))


m_ps <- glm(form, family=binomial(), data=reg_form)
summary(m_ps)
```

Also, interestingly enough, the only significant elements of
this logistic model (95%) are: `prev_topic_3_score`, `prev_cmv_com_avg_lag`, 
and `prev_cmv_sub_avg_direct_coms`. In other words, it appears that, when
controlling for the aforementioned important variables, it appears that earlier
comments, attempting to change the opinion of certain topics, when there are
fewer direct replies leads to a higher predicted probability of `delta_treatment`.

## Examine Common Support

```{r apply_ps}
library(modelr)
logit2prob <- function(x){
  (exp(x) / (1 + exp(x)))
}

reg_form <- reg_form %>%
  add_predictions(m_ps) %>%
  mutate(prob = logit2prob(pred))


reg_form %>%
  ggplot(aes(x = prob)) +
  geom_histogram(bins = 10) + 
  facet_wrap(as.formula(paste("~", "delta_treatment"))) +
  xlab("Prop-Score") +
  labs(title = "Propensity Score by Treatment Group")
  
```

Looking at this histogram, one can see that the task of predicting
`delta_treatment` as "Delta" appears to be difficult (assuming a 50% probability
cutoff). However, there does appear to be a viable region of common support, as
we can see in the table below.

```{r support_table}
(support_table <- reg_form %>%
  group_by(delta_treatment) %>%
  summarise(count = n(), min_prob = min(prob), max_prob = max(prob)))
```

There are `r 644 + 109` observations in total, but those falling outside of the
common support will be omitted during the stratification procedure.

## Stratification

Utilizing R's `MatchIt` (@matchit) package we utilize the propensity score calculated above
to stratify the sample into 3 separate subclasses. While this is unfortunately
fewer than I would have liked, but after removing observations falling outside
the common support there are only `604` left. Even with the reduced number of
strata some balance statistics are still not ideal.

```{r matching_alg, warning=F, message=F}
# reg_form_cov <- c("prev_unique_subs", "prev_avg_edits", "prev_cmv_coms", "prev_avg_score")
# reg_form_cov <- c("prev_avg_edits")
reg_form_nomiss <- reg_form %>%  # MatchIt does not allow missing values
  mutate(delta_treatment = ifelse(delta_treatment == "No Delta", 0, 1)) %>%
  na.omit()
form <- as.formula(paste("delta_treatment ~ ", paste0(reg_form_cov, collapse = " + ")))

# Have binary coding!
mod_match <- matchit(form,
                     method = "subclass", data = reg_form_nomiss,
                     subclass = 3,
                     discard = "both",
                     reestimate = F
                     )
dta_m <- match.data(mod_match)
t <- summary(mod_match, standardize = T)

(t$sum.matched)
(t$qn)
ot <- plot(mod_match, type = "jitter")
(ot)
```

These strata are definitely not of equal size, at least between strata
(subclasses). Only subclass #3 has it's treatment/control split approximately
equal. Additionally, looking at the balance statistics for certain covariates is
concerning. However, since I am doing propensity score stratification, I am more
concerned with the balance for the propensity score, which is `distance` above, 
and the statistics concerning it compare favorably to the covariates that help comprise it. ([Legend for balance statistics.](https://r.iq.harvard.edu/docs/matchit/2.4-20/The__TT_summary_TT__Co.html))

Additionally, a "jitter" plot showing the propensity scores of units matched into a strata and those that were not (i.e. those outside the common support), is provided.

# Average Treatment Effect Estimation

Now, I utilize the R package `Zelig` (@zelig) to estimate the ATE across each subclass
with a 95% confidence interval. Our outcome of interest is
`outcome_deltas_given`, which indicates the number of deltas each subject author
awarded in their CMV submissions *after* their period of CMV comments which I
utilized to calculate their propensity score.

```{r zelig_ate, message=FALSE, warning=F}
library(Zelig)

check_form <- paste("outcome_deltas_given ~ delta_treatment + ",
                    paste0(reg_form_cov, 
                           "+ prev_cmv_subs", collapse = " + "))
zelig.out <- zelig(check_form, data = match.data(mod_match),
                   by = "subclass", model = "ls",
                   cite = F)

x.out1 <- setx(zelig.out, data = match.data(mod_match, "delta_treatment"), 
               fn = NULL, cond = TRUE)
s.out1 <- sim(zelig.out, x = x.out1, y = "outcome_deltas_given")
(sum <- summary(s.out1))
```

The key take away from the above (admittedly cluttered) figure are the `2.5%`
and `97.5%` numbers under `pv` (predicted value). These are `Zelig`'s way of
indicating the 95% confidence interval for the ATE on `outcome_deltas_given`.
Note that none of these confidence intervals indicate a statistically significant 
effect. Additionally, because `outcome_deltas_given` inherently relies on the number 
of CMV submissions the subject authors made, we include it as a variable when estimating the ATE.

# Shortcomings and Design Decisions

Unfortunately, even as I was trying to push this observational data towards
something more quasi-experimental, I realized I had a lot of leeway in how
exactly I framed the problem and the elements comprising it.

## Treatment Definition and Effect

`delta_treatment`, though defined as a binary treatment variable, actually
flattens any value of deltas received above 1 to 1. That is, the treatment is
more accurately defined as an ordinal multi-valued treatment, as it is possible
for the subject authors to receive anywhere 0 to the number of CMV comments they
made deltas before they began their own CMV submissions. However, given the 
relative sparsity of higher valued deltas, I elected to binarize the treatment.
Binarization also made things like propensity score stratification less complicated. 

## Missing Data

Reddit Submissions can be "live" for a period of 6 months before further activity
on the submission (editing, new comments) is suspended, effectively "archiving"
the it. Within that 6 month period, however, comments and submissions can either 
be deleted by the user, or removed by moderators of a subreddit for violating
rules. When gathering the data used for this exercise, I ensured that all
submissions utilized in the data were over 6 months old, eliminating the
possibility of new activity. Unfortunately, a not-insignificant amount of
submissions and comments gathered were either deleted or removed, eliminating the link 
back to their original authors. It would be naive to think that this pattern of 
missing data is random in nature, and thus this leaves one of a few sore marks
on this paper.

Additionally, there are many more CMV submissions and comments available for 
inference. I was unable to gather these due to time constraints, but gathering them may have allowed for a greater number of strata, or at least more balanced strata.

## Stable Unit Treatment Value Assumption (SUTVA)

This requires that the potential outcome (`outcome_deltas_given`) of one unit
is not affected by the particular treatment assignment (`delta_treatment`) of
other units. However, it is quite easy to think of a counter-example in which
this assumption is violated.

There are two subject authors, `S0` and `S1`, `S0` actively posted CMV comments
from `time = 0` to `time = 5` while `S1` actively posted CMV submissions over the
same period. If `S0` posted comments on *any* of `S1`'s submissions, then (SUTVA)
is violated, because `S1`'s `outcome_deltas_given` then has direct interaction
with `S0`'s `delta_treatment` value.

```{r sutva_investigate}
sutva_info <- inner_join(cmv_coms, sub_auths_min_date) %>%
  # Don't count CMV comments posted on their own posts (Impossible to get a delta from yourself!)
  inner_join(cmv_subs %>% select(author, reddit_id, date_utc, direct_comments,
                                 topic_1, topic_2, topic_3, topic_4, topic_5, topic_6, topic_7) 
             %>% rename(sub_auth = author, sub_id = reddit_id, sub_date = date_utc), 
             by=c("parent_submission_id" = "sub_id")) %>%
  filter(sub_auth != author) %>%
  filter(date_utc < first_cmv_date)


sutva_violations <- sutva_info %>%
  filter((author %in% subject_authors) & (sub_auth %in% subject_authors))

perct <- round(100 * nrow(sutva_violations) / nrow(sutva_info), 2)
```

Just how prevalent is this problem? Among the `r nrow(sutva_info)` total CMV comments
used to create information on the subject author's, `r nrow(sutva_violations)`
of these comments (`r perct`%) violate the SUTVA assumption. Out of the `r nrow(reg_form)` subject authors in the analysis,
`r length(unique(sutva_violations$author))` have violating comments.

```{r}
reg_form %>%
  ggplot(aes(x = prev_cmv_coms)) +
  geom_density() + 
  labs(title = "Subject author's previous CMV Comments")
```

While it's possible to remove the CMV comments that violate the SUTVA assumption,
there are so many subject authors with only a single CMV comment, that doing this
thins the data too much, such that only 2 or fewer strata can be utilized, leaving too much selection bias in the problem. At the same time, this does not significantly affect the results from above, as there is still no evidence of `delta_treatment` having a significant effect on `outcome_deltas_given`.

## CMV Submission Content/Topic

Given that one of the central topics of this paper is the changing of opinions (via receiving and giving deltas), the topics and content of the opinions would definitely have an impact on how difficult they may be to change. Before, I mentioned that each of the CMV Submissions the subject authors commented on was given 7 "topic scores" using LDA topic modelling in an attempt to shed some light on the subject matter, this in turn was integrated into the propensity score. Additionally, I experimented (as a sort of rough sensitivty analysis) with changing the number of assumed topics (`k`), as well as including the average topic scores of each subject author's CMV Submissions as a control variable in the calculation of ATE. However prudent any of these experiments may have been there was still no change in the non-significant takeaway result.

Topic modelling is not the only way to glean information from the content of a CMV Submission. @tan2016winning utilized Markdown syntax, pronoun types, link types, and the number of paragraphs, among others. Such features would have been useful to have, especially given the past history of using propensity score measures with hundreds of covariates! Unfortunately, I am one person, and not 4 from Cornell.

## User Identification and Demographics

Because new Reddit accounts can be created relatively quickly, there is no 
guarantee that the number of subject authors is exactly the number of unique
individuals in the study. That is, some subject authors that may have otherwise
been subject authors were not counted as such because they split up their
previous CMV comments to one account and their submissions to another (or
vice-versa). Unlike more traditional sociological studies utilizing causal
inference methods, I have little reliable information that identifies and
characterizes the subject authors.

# Conclusion

In this paper I attempted to utilize data present in r/ChangeMyView, a unique
community of Reddit, and propensity score stratification, to find evidence of
reciprocation in opinion malleability. However, given the observational nature
of the data, the sparcity stemming from the way in which I chose to frame the
problem (treatment/outcome), and the actual scale of the NLP problem, I found
the task rather difficult.

My final result was able to utilize a lower number of strata than I would have
liked, letting some bias remain. Without knowing the nature of that bias, I am
a little wary of both the null result, and any changes brought about by
sensitivty analysis, which in this case (not shown) was simply including quadratic terms and
interactions of variables with differing variances and correlations, between the treatment groups.

Even with my disappointment I have a newfound respect of the precision and
diligence required to utilize causaul inference methods with more experimental and more traditional data.

\newpage

# Citations